{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_addons as tfa\n",
    "from sklearn.metrics import f1_score, recall_score, roc_auc_score, r2_score\n",
    "import numpy as np\n",
    "import os\n",
    "import os.path\n",
    "import sys\n",
    "import csv\n",
    "import time\n",
    "import json\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from os import path\n",
    "import random as rd\n",
    "import h5py\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the path to save the trained model\n",
    "h5d_file_path = \"./A549/Model/model_regression.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load gene expression data \n",
    "label_data = pd.read_csv(\"./A549/Data/A549_RNAseq_regression.txt\", delimiter=\"\\t\")\n",
    "label_data = label_data.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The expression is the prediction target of iSEGnet. It is a array with shape (number_of_genes, 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.77010822],\n",
       "       [0.        ],\n",
       "       [3.59429401],\n",
       "       ...,\n",
       "       [0.        ],\n",
       "       [2.37304356],\n",
       "       [2.0333976 ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iSEGnet has two input data. One is the one-hot coded sequence data. Another is the epigenetics data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('./A549/Data/h5file/epi_data.h5', 'r') as hf:\n",
    "    epigenetics_input_data = hf['dataset_1'][:]\n",
    "\n",
    "with h5py.File('./A549/Data/h5file/seq_data.h5', 'r') as hf:\n",
    "    sequence_input_data = hf['dataset_1'][:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In the data here, each row is the input data for one gene. The regulatory region has the length of 7000 bps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23364, 49000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epigenetics_input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23364, 28000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_input_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For the default settings, we only use 2500 bps around TSS and TTS. Please go to our paper for more details. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DNase_index = np.array(range(4000, 6500))\n",
    "H3K4me1_index = np.array(range(11000, 13500))\n",
    "H3K4me3_index = np.array(range(18000, 20500))\n",
    "H3K9me3_index = np.array(range(25000, 27500))\n",
    "H3K27me3_index = np.array(range(32000, 34500))\n",
    "H3K36me3_index = np.array(range(39000, 41500))\n",
    "WGBS_index = np.array(range(46000, 48500))\n",
    "epi_index = np.concatenate((DNase_index, H3K4me1_index, H3K4me3_index,\n",
    "                            H3K9me3_index, H3K27me3_index, H3K36me3_index,WGBS_index), axis = 0)\n",
    "seq_index = np.array(range(16000, 26000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge all the data into one single 2-D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "epigenetics_input_data = epigenetics_input_data[:, epi_index]\n",
    "sequence_input_data = sequence_input_data[:, seq_index]\n",
    "\n",
    "All_data = np.concatenate((epigenetics_input_data, sequence_input_data), axis = 1)\n",
    "All_data = np.concatenate((All_data, label_data), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23364, 27501)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "All_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomly shuffle the genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_oder_path = \"./random_order_path.txt\"\n",
    "\n",
    "if os.path.isfile(random_oder_path):\n",
    "    random_order = pd.read_csv(random_oder_path, delimiter=\"\\t\", header = None)[0].values.tolist()\n",
    "else:\n",
    "    random_order = range(0, All_data.shape[0])\n",
    "    random_order = list(random_order)\n",
    "    rd.shuffle(random_order)\n",
    "    rd.shuffle(random_order)\n",
    "    np.savetxt(random_oder_path, random_order, fmt='%i')\n",
    "\n",
    "All_data = All_data[random_order]\n",
    "All_data = All_data[All_data[:, All_data.shape[1]-1] != 0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete the data to release memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del epigenetics_input_data\n",
    "del sequence_input_data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernal_num1 = 32                   \n",
    "kernal_num2 = 64\n",
    "kernal_size = 20\n",
    "L2 = 1e-4\n",
    "drop_rate = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the training set, validation set and testing set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_epi = All_data[0:10004, 0:17500]\n",
    "train_data_seq = All_data[0:10004, 17500:27500]\n",
    "train_data_label = All_data[0:10004, 27500:27501]\n",
    "valid_data_epi = All_data[10004:13339, 0:17500]\n",
    "valid_data_seq = All_data[10004:13339, 17500:27500]\n",
    "valid_data_label = All_data[10004:13339, 27500:27501]\n",
    "test_data_epi = All_data[13339:, 0:17500]\n",
    "test_data_seq = All_data[13339:, 17500:27500]\n",
    "test_data_label = All_data[13339:, 27500:27501]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iSEGnet framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Epigenetics data input module. It has two convolutional layers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "epi_input = keras.Input(shape = (17500,), name=\"epi_input\", dtype=tf.float32)\n",
    "epi_input_reshape = layers.Reshape(target_shape = (7, 2500, 1))(epi_input)\n",
    "epi_input_reshape_transpose = layers.Permute((2, 1, 3))(epi_input_reshape)\n",
    "epi_input_padding = layers.ZeroPadding2D(padding = ((10, 9), (0, 0)))(epi_input_reshape_transpose)\n",
    "epi_conv = layers.Conv2D(filters=kernal_num1, kernel_size=(kernal_size, 7),\n",
    "                         activation=None, kernel_regularizer=tf.keras.regularizers.l2(L2),\n",
    "                         padding = \"valid\", use_bias = False)(epi_input_padding)\n",
    "epi_conv_bn = layers.BatchNormalization()(epi_conv)\n",
    "epi_conv_act = layers.Activation('relu')(epi_conv_bn)\n",
    "epi_conv_dp = layers.Dropout(drop_rate)(epi_conv_act)\n",
    "epi_input_padding_l2 = layers.ZeroPadding2D(padding = ((5, 4), (0, 0)))(epi_conv_dp)\n",
    "epi_conv_l2 = layers.Conv2D(filters=kernal_num2, kernel_size=(kernal_size, 1),\n",
    "                         activation=None, kernel_regularizer=tf.keras.regularizers.l2(L2),\n",
    "                         padding = \"valid\")(epi_input_padding_l2)\n",
    "epi_conv_bn_l2 = layers.BatchNormalization()(epi_conv_l2)\n",
    "epi_conv_act_l2 = layers.Activation('relu')(epi_conv_bn_l2)\n",
    "epi_conv_dp_l2 = layers.Dropout(drop_rate)(epi_conv_act_l2)\n",
    "epi_pool_l2 = layers.AveragePooling2D(pool_size=(5,1), strides = 5, padding = \"valid\")(epi_conv_dp_l2)\n",
    "seq_input = keras.Input(shape = (10000,), name=\"seq_input\", dtype=tf.float32)\n",
    "seq_input_reshape = layers.Reshape(target_shape = (2500, 4, 1))(seq_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sequence data input module. It has two convolutional layers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_input_padding = layers.ZeroPadding2D(padding = ((10, 9), (0, 0)))(seq_input_reshape)\n",
    "seq_conv = layers.Conv2D(filters=kernal_num1,kernel_size=(kernal_size, 4), activation=None, \n",
    "                         kernel_regularizer=tf.keras.regularizers.l2(L2), \n",
    "                         padding = \"valid\", use_bias = False)(seq_input_padding)\n",
    "seq_conv_bn = layers.BatchNormalization()(seq_conv)\n",
    "seq_conv_act = layers.Activation('relu')(seq_conv_bn)\n",
    "seq_conv_dp = layers.Dropout(drop_rate)(seq_conv_act)\n",
    "seq_input_padding_l2 = layers.ZeroPadding2D(padding = ((5, 4), (0, 0)))(seq_conv_dp)\n",
    "seq_conv_l2 = layers.Conv2D(filters=kernal_num2, kernel_size=(kernal_size, 1),\n",
    "                         activation=None, kernel_regularizer=tf.keras.regularizers.l2(L2),\n",
    "                         padding = \"valid\")(seq_input_padding_l2)\n",
    "seq_conv_bn_l2 = layers.BatchNormalization()(seq_conv_l2)\n",
    "seq_conv_act_l2 = layers.Activation('relu')(seq_conv_bn_l2)\n",
    "seq_conv_dp_l2 = layers.Dropout(drop_rate)(seq_conv_act_l2)\n",
    "seq_pool_l2 = layers.AveragePooling2D(pool_size=(5,1), strides = 5, padding = \"valid\")(seq_conv_dp_l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contatenate the outputs from two modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_input = tf.concat([epi_pool_l2,seq_pool_l2], 2)\n",
    "merged_input_padding = layers.ZeroPadding2D(padding = ((1, 0), (0, 0)))(merged_input)\n",
    "merged_conv = layers.Conv2D(filters=126, kernel_size=(2, 2), \n",
    "                            activation=None, kernel_regularizer=tf.keras.regularizers.l2(L2),\n",
    "                            padding = \"valid\")(merged_input_padding)\n",
    "merged_conv_bn = layers.BatchNormalization()(merged_conv)\n",
    "merged_conv_act = layers.Activation('relu')(merged_conv_bn)\n",
    "merged_conv_dp = layers.Dropout(drop_rate)(merged_conv_act)\n",
    "merged_conv_l2 = layers.Conv2D(filters=64, kernel_size=(1, 1), \n",
    "                            activation=None, kernel_regularizer=tf.keras.regularizers.l2(L2),\n",
    "                            padding = \"valid\")(merged_conv_dp)\n",
    "merged_conv_bn_l2 = layers.BatchNormalization()(merged_conv_l2)\n",
    "merged_conv_act_l2 = layers.Activation('relu')(merged_conv_bn_l2)\n",
    "merged_conv_dp_l2 = layers.Dropout(drop_rate)(merged_conv_act_l2)\n",
    "merged_pool_l2 = layers.AveragePooling2D(pool_size=(5,1), strides = 5, padding = \"valid\")(merged_conv_dp_l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fully connected network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat = layers.Flatten()(merged_pool_l2)\n",
    "dense1 = layers.Dense(256, activation=None, kernel_regularizer=tf.keras.regularizers.l2(L2))(flat)\n",
    "dense1_bn = layers.BatchNormalization()(dense1)\n",
    "dense1_act = layers.Activation('relu')(dense1_bn)\n",
    "dense1_dp = layers.Dropout(drop_rate)(dense1_act)\n",
    "dense2 = layers.Dense(64, activation=None, kernel_regularizer=tf.keras.regularizers.l2(L2))(dense1_dp)\n",
    "dense2_bn = layers.BatchNormalization()(dense2)\n",
    "dense2_act = layers.Activation('relu')(dense2_bn)\n",
    "dense2_dp = layers.Dropout(drop_rate)(dense2_act)\n",
    "dense3 = layers.Dense(16, activation=None, kernel_regularizer=tf.keras.regularizers.l2(L2))(dense2_dp)\n",
    "dense3_bn = layers.BatchNormalization()(dense3)\n",
    "dense3_act = layers.Activation('relu')(dense3_bn)\n",
    "output_d = layers.Dense(1, activation=None, kernel_regularizer=tf.keras.regularizers.l2(L2))(dense3_act)\n",
    "output = layers.Activation('relu', name= 'expression')(output_d)\n",
    "model = keras.Model(inputs=[epi_input, seq_input], outputs=output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set model compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=['mse'], \n",
    "              optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "              metrics={\"expression\" : tfa.metrics.RSquare(y_shape=(1,))})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### set checkpoint to save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = keras.callbacks.ModelCheckpoint(h5d_file_path, monitor='val_r_square', \n",
    "                             verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set the early stoppping function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = keras.callbacks.EarlyStopping(monitor='val_r_square', mode='max', verbose=1, patience=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x = [train_data_epi, train_data_seq],\n",
    "          y = train_data_label,\n",
    "          validation_data = ([valid_data_epi, valid_data_seq], valid_data_label),\n",
    "          batch_size = 100,\n",
    "          epochs=100, callbacks=[es,checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(h5d_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate the R sequare value on the testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expression_gene_prediction = model.predict(x = [test_data_epi, test_data_seq])\n",
    "\n",
    "R2_value = [r2_score(test_data_label, expression_gene_prediction)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
